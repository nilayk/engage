# Engage Configuration
# Copy this file to .env and customize as needed

# Server port
PORT=3000

# Ollama AI Configuration
OLLAMA_HOST=http://ollama:11434

# LLM model for AI cleanup (used to clean up HTML formatting)
# Options: qwen2.5-coder:1.5b (fast), qwen2.5-coder:3b (better quality), phi3:mini
OLLAMA_MODEL=qwen2.5-coder:1.5b

# Embedding model for smart extraction (used to identify main content)
# Options: nomic-embed-text (recommended), all-minilm
EMBEDDING_MODEL=nomic-embed-text

# Context window size in tokens (increase for longer pages, requires more VRAM)
# qwen2.5-coder supports up to 32768. Default: 16384
OLLAMA_CONTEXT_SIZE=16384

# AI generation timeout in milliseconds (increase for slower hardware or larger pages)
# Default: 180000 (3 minutes)
OLLAMA_GENERATE_TIMEOUT=180000